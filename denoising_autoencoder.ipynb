{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKJesW4g56-9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Flatten the images (convert 28x28 images to 784-dimensional vectors)\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
      ],
      "metadata": {
        "id": "Fz9ss44d6CG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "474ead13-d1f8-4644-df26-80da9430d3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
      ],
      "metadata": {
        "id": "hckxof5Q6cNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input layer\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "# Encoder\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "\n",
        "# Decoder\n",
        "decoded = Dense(128, activation='relu')(encoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fxV-_Hx6Dn7",
        "outputId": "1e5dac83-95e2-483c-bc96-f338d36845fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train_noisy, x_train, epochs=10, batch_size=256, shuffle=True, validation_data=(x_test_noisy, x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iPiAjkr6HUU",
        "outputId": "8299bf83-08e3-4565-847a-188d1ec25c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 5s 16ms/step - loss: 0.2400 - val_loss: 0.1746\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.1628 - val_loss: 0.1514\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1472 - val_loss: 0.1414\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1393 - val_loss: 0.1350\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.1339 - val_loss: 0.1315\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1301 - val_loss: 0.1274\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1270 - val_loss: 0.1251\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1246 - val_loss: 0.1229\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.1228 - val_loss: 0.1211\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1212 - val_loss: 0.1199\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b55ca7ee590>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the autoencoder model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "\n",
        "mse = mean_squared_error(x_test, decoded_imgs)\n",
        "psnr = peak_signal_noise_ratio(x_test, decoded_imgs)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Peak Signal-to-Noise Ratio (PSNR): {psnr}\")\n",
        "\n",
        "# print(f\"Mean Squared Error: {round(mse*100,2)}%\")\n",
        "# print(f\"Peak Signal-to-Noise Ratio (PSNR): {round(psnr*100,2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1gZQloGfYuu",
        "outputId": "1dd14e34-4672-4e40-b77c-26fc7ada614b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.018790461122989655\n",
            "Peak Signal-to-Noise Ratio (PSNR): 17.260601985507364\n",
            "Mean Squared Error: 1.88%\n",
            "Peak Signal-to-Noise Ratio (PSNR): 1726.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
        "\n",
        "n = 1  # Number of images to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstructed images\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "zgK8zYnZ6JPo",
        "outputId": "18d8159b-b1ac-49fa-881b-648c887bbbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.save(\"trained_denoising_autoencoder_model.h5\")"
      ],
      "metadata": {
        "id": "jGQWdjFa7-yF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1fe057-be70-4d0e-b8b4-aed88d28b1bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('trained_denoising_autoencoder_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hRKAhsS23__X",
        "outputId": "29fb28f7-99a8-4c36-cc5d-467a49e89d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_32be4c52-1770-4f46-ac5a-2eb46aa18724\", \"autoencoder_model.h5\", 2660416)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : Convert .h5 to .json for tensorflowjs by Command prompt\n",
        "\n",
        "\\> tensorflowjs_converter --input_format=keras _path_/autoencoder_model.h5 _path_"
      ],
      "metadata": {
        "id": "zUroK7jUAPTA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eFFx_oSSPiEF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}